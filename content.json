{"meta":{"title":"League of Data","subtitle":null,"description":"HOW NOT TO BE WRONG ?","author":"Xiao蜗牛","url":"http://yoursite.com"},"pages":[{"title":"标签","date":"2017-07-13T15:05:02.000Z","updated":"2017-07-13T15:12:45.481Z","comments":true,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""},{"title":"关于","date":"2017-07-13T15:07:37.000Z","updated":"2017-07-16T17:29:11.088Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":"123456789101112131415161718&#123; name: &apos;宫保伟&apos; age: 23, gender: &apos;男&apos;, address: &apos;广东省广州市&apos;, education: &apos;本科/延边大学&apos;, Github: &apos;https://github.com/guuboi&apos;, email: &apos;guuboi@163.com&apos;, skills: [ [&apos;Excel&apos;, &apos;Spss&apos;, &apos;R语言&apos;, &apos;Python&apos;], [&apos;MySql&apos;, &apos;Oracle&apos;, &apos;Hive&apos;, &apos;Pig&apos;], [&apos;数据分析&apos;, &apos;自然语言处理&apos;], [&apos;Linux&apos;] ], description: &apos;喜欢新事物，关注nlp前沿动态，对新的技术有追求； 喜欢研究，喜欢分析，喜欢 coding。&apos;&#125;"},{"title":"分类","date":"2017-07-13T15:07:18.000Z","updated":"2017-07-13T15:12:14.966Z","comments":true,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"","slug":"01-advanced-r-data-structure","date":"2017-07-17T14:16:47.494Z","updated":"2017-07-17T14:13:57.951Z","comments":true,"path":"2017/07/17/01-advanced-r-data-structure/","link":"","permalink":"http://yoursite.com/2017/07/17/01-advanced-r-data-structure/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"基于gensim的Wiki百科中文word2vec训练","slug":"11-word2vec-based-on-gensim","date":"2017-07-13T07:30:16.000Z","updated":"2017-07-16T17:11:58.395Z","comments":true,"path":"2017/07/13/11-word2vec-based-on-gensim/","link":"","permalink":"http://yoursite.com/2017/07/13/11-word2vec-based-on-gensim/","excerpt":"Word2Vec简介Word2Vec是词（Word）的一种表示方式。不同于one-hot vector，word2vec可以通过计算各个词之间的距离，来表示词与词之间的相似度。word2vec提取了更多的特征，它使得具有相同上下文语义的词尽可能离得近一些，而不太相关的词尽可能离得较远一些。例如，【腾讯】和【网易】两个词向量将会离得很近，同理【宝马】和【保时捷】两个词向量将会离得很近。而【腾讯】和【宝马】/【保时捷】，【网易】和【宝马】/【保时捷】将会离得较远一些。因为【腾讯】和【网易】都同属于互联网类目，而【宝马】和【保时捷】都同属于汽车类目。人以类聚，物以群分嘛！互联网圈子中谈的毕竟都是互联网相关的话题，而汽车圈子中谈论的都是和汽车相关的话题。","text":"Word2Vec简介Word2Vec是词（Word）的一种表示方式。不同于one-hot vector，word2vec可以通过计算各个词之间的距离，来表示词与词之间的相似度。word2vec提取了更多的特征，它使得具有相同上下文语义的词尽可能离得近一些，而不太相关的词尽可能离得较远一些。例如，【腾讯】和【网易】两个词向量将会离得很近，同理【宝马】和【保时捷】两个词向量将会离得很近。而【腾讯】和【宝马】/【保时捷】，【网易】和【宝马】/【保时捷】将会离得较远一些。因为【腾讯】和【网易】都同属于互联网类目，而【宝马】和【保时捷】都同属于汽车类目。人以类聚，物以群分嘛！互联网圈子中谈的毕竟都是互联网相关的话题，而汽车圈子中谈论的都是和汽车相关的话题。 我们怎么得到一个词的word2vec呢？下面我们将介绍如何使用python gensim得到我们想要的词向量。总的来说，包括以下几个步骤： wiki中文数据预处理 文本数据分词 gensim word2vec训练 wiki中文数据预处理首先，下载wiki中文数据：zhwiki-latest-pages-articles.xml.bz2。因为zhwiki数据中包含很多繁体字，所以我们想获得简体语料库，接下来需要做以下两件事： 使用gensim模块中的WikiCorpus从bz2中获取原始文本数据 使用OpenCC将繁体字转换为简体字 WikiCorpus获取原始文本数据数据处理的python代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940from __future__ import print_functionfrom gensim.corpora import WikiCorpusimport jiebaimport codecsimport osimport sixfrom gensim.models import Word2Vecfrom gensim.models.word2vec import LineSentenceimport multiprocessing class Config: data_path = &apos;xxx/zhwiki&apos; zhwiki_bz2 = &apos;zhwiki-latest-pages-articles.xml.bz2&apos; zhwiki_raw = &apos;zhwiki_raw.txt&apos; zhwiki_raw_t2s = &apos;zhwiki_raw_t2s.txt&apos; zhwiki_seg_t2s = &apos;zhwiki_seg.txt&apos; embedded_model_t2s = &apos;embedding_model_t2s/zhwiki_embedding_t2s.model&apos; embedded_vector_t2s = &apos;embedding_model_t2s/vector_t2s&apos; def dataprocess(_config): i = 0 if six.PY3: output = open(os.path.join(_config.data_path, _config.zhwiki_raw), &apos;w&apos;) output = codecs.open(os.path.join(_config.data_path, _config.zhwiki_raw), &apos;w&apos;) wiki = WikiCorpus(os.path.join(_config.data_path, _config.zhwiki_bz2), lemmatize=False, dictionary=&#123;&#125;) for text in wiki.get_texts(): if six.PY3: output.write(b&apos; &apos;.join(text).decode(&apos;utf-8&apos;, &apos;ignore&apos;) + &apos;\\n&apos;) else: output.write(&apos; &apos;.join(text) + &apos;\\n&apos;) i += 1 if i % 10000 == 0: print(&apos;Saved &apos; + str(i) + &apos; articles&apos;) output.close() print(&apos;Finished Saved &apos; + str(i) + &apos; articles&apos;)config = Config()dataprocess(config) 使用OpenCC将繁体字转换为简体字这里，需要预先安装OpenCC，关于OpenCC在linux环境中的安装方法，请参考这篇文章。仅仅需要两行linux命令就可以完成繁体字转换为简体字的认为，而且速度很快。12$ cd /xxx/zhwiki/$ opencc -i zhwiki_raw.txt -o zhwiki_t2s.txt -c t2s.json 文本数据分词对于分词这个任务，我们直接使用了python的jieba分词模块。你也可以使用哈工大的ltp或者斯坦福的nltk python接口进行分词，准确率及权威度挺高的。不过这两个安装的时候会花费很长时间，尤其是斯坦福的。关于jieba的分词处理代码，参考如下：1234567891011121314151617181920212223242526272829303132def is_alpha(tok): try: return tok.encode(&apos;ascii&apos;).isalpha() except UnicodeEncodeError: return Falsedef zhwiki_segment(_config, remove_alpha=True): i = 0 if six.PY3: output = open(os.path.join(_config.data_path, _config.zhwiki_seg_t2s), &apos;w&apos;, encoding=&apos;utf-8&apos;) output = codecs.open(os.path.join(_config.data_path, _config.zhwiki_seg_t2s), &apos;w&apos;, encoding=&apos;utf-8&apos;) print(&apos;Start...&apos;) with codecs.open(os.path.join(_config.data_path, _config.zhwiki_raw_t2s), &apos;r&apos;, encoding=&apos;utf-8&apos;) as raw_input: for line in raw_input.readlines(): line = line.strip() i += 1 print(&apos;line &apos; + str(i)) text = line.split() if True: text = [w for w in text if not is_alpha(w)] word_cut_seed = [jieba.cut(t) for t in text] tmp = &apos;&apos; for sent in word_cut_seed: for tok in sent: tmp += tok + &apos; &apos; tmp = tmp.strip() if tmp: output.write(tmp + &apos;\\n&apos;) output.close()zhwiki_segment(config) gensim word2vec训练python的gensim模块提供了word2vec训练，为我们模型的训练提供了很大的方便。关于gensim的使用方法，可以参考基于Gensim的Word2Vec实践。本次训练的词向量大小size为50，训练窗口为5，最小词频为5，并使用了多线程，具体代码如下：123456789101112131415161718192021def word2vec(_config, saved=False): print(&apos;Start...&apos;) model = Word2Vec(LineSentence(os.path.join(_config.data_path, _config.zhwiki_seg_t2s)), size=50, window=5, min_count=5, workers=multiprocessing.cpu_count()) if saved: model.save(os.path.join(_config.data_path, _config.embedded_model_t2s)) model.save_word2vec_format(os.path.join(_config.data_path, _config.embedded_vector_t2s), binary=False) print(&quot;Finished!&quot;) return model def wordsimilarity(word, model): semi = &apos;&apos; try: semi = model.most_similar(word, topn=10) except KeyError: print(&apos;The word not in vocabulary!&apos;) for term in semi: print(&apos;%s,%s&apos; % (term[0],term[1]))model = word2vec(config, saved=True) word2vec训练已经完成，我们得到了想要的模型以及词向量，并保存到本地。下面我们分别查看同【宝马】和【腾讯】最相近的前10个词语。可以发现：和【宝马】相近的词大都属于汽车行业，而且是汽车品牌；和【腾讯】相近的词大都属于互联网行业。1234567891011121314151617181920212223&gt;&gt;&gt; wordsimilarity(word=u&apos;宝马&apos;, model=model)保时捷,0.92567974329固特异,0.888278841972劳斯莱斯,0.884045600891奥迪,0.881808757782马自达,0.881799697876亚菲特,0.880708634853欧宝,0.877104878426雪铁龙,0.876984715462玛莎拉蒂,0.868475496769桑塔纳,0.865387916565&gt;&gt;&gt; wordsimilarity(word=u&apos;腾讯&apos;, model=model)网易,0.880213916302优酷,0.873666107655腾讯网,0.87026232481广州日报,0.859486758709微信,0.835543811321天涯社区,0.834927380085李彦宏,0.832848489285土豆网,0.831390202045团购,0.829696238041搜狐网,0.825544642448 附相关数据及代码，包含：简体字转换后文本，分词后文本，以及50维word2vec词向量。","categories":[{"name":"自然语言处理","slug":"自然语言处理","permalink":"http://yoursite.com/categories/自然语言处理/"}],"tags":[{"name":"gensim","slug":"gensim","permalink":"http://yoursite.com/tags/gensim/"},{"name":"word2vec","slug":"word2vec","permalink":"http://yoursite.com/tags/word2vec/"},{"name":"wiki","slug":"wiki","permalink":"http://yoursite.com/tags/wiki/"}]},{"title":"OpenCC - 简体繁体转换","slug":"12-opencc-tools","date":"2017-07-12T07:30:16.000Z","updated":"2017-07-16T17:03:59.620Z","comments":true,"path":"2017/07/12/12-opencc-tools/","link":"","permalink":"http://yoursite.com/2017/07/12/12-opencc-tools/","excerpt":"最近使用中文维基百科数据训练Word2Vec时，发现数据里面包含了很多繁体字，这就很尴尬了。这时候就知道OpenCC的强大了。哈哈，本来打算直接使用python里面的opencc模块的，但是在安装，编译opencc时遇到了各种错误。花费了很长时间，终于安装成功，但是文本处理起来效率很低。最终选择了直接在linux下安装OpenCC，处理的效率着实安慰了我受伤的心 – 很快，特别快。","text":"最近使用中文维基百科数据训练Word2Vec时，发现数据里面包含了很多繁体字，这就很尴尬了。这时候就知道OpenCC的强大了。哈哈，本来打算直接使用python里面的opencc模块的，但是在安装，编译opencc时遇到了各种错误。花费了很长时间，终于安装成功，但是文本处理起来效率很低。最终选择了直接在linux下安装OpenCC，处理的效率着实安慰了我受伤的心 – 很快，特别快。 好啦，接下来总结下OpenCC的安装方法，万一以后又用到它了呢？主要参考这篇博客： 检查下linux环境下是否已经安装cmake以及git，如果没有，那就通过yum安装好。 12$ yum install cmake$ yum install git 克隆下OpennCC开源项目OpennCC开源项目。 1$ git clone https://github.com/BYVoid/OpenCC 编译OpenCC 123$ cd OpenCC$ make$ make install 创建libopencc.so.2链接 如果不知道libopencc.so.2的路径，可以通过find / -name libopencc.so.2查找。1$ ln -s /usr/lib/libopencc.so.2 /usr/lib64/libopencc.so.2 通过查看 OpenCC 版本，检查OpenCC是否已经安装成功 1$ opencc --version 测试用例 12345678# 繁体转简体$ echo &apos;歐幾里得 西元前三世紀的希臘數學家&apos; | opencc -c t2s欧几里得 西元前三世纪的希腊数学家# 简体转繁体$ echo &apos;欧几里得 西元前三世纪的希腊数学家&apos; | opencc -c s2t歐幾里得 西元前三世紀的希臘數學家# 可以通过以下方式直接对文件进行繁简转换$ opencc -i zhwiki_raw.txt -o zhwiki_t2s.txt -c t2s.json","categories":[{"name":"辅助工具","slug":"辅助工具","permalink":"http://yoursite.com/categories/辅助工具/"}],"tags":[{"name":"wiki","slug":"wiki","permalink":"http://yoursite.com/tags/wiki/"},{"name":"opencc","slug":"opencc","permalink":"http://yoursite.com/tags/opencc/"}]},{"title":"pyltp - 哈工大语言云python接口使用说明","slug":"13-hitltp-tools","date":"2017-07-10T07:30:16.000Z","updated":"2017-07-16T17:18:39.404Z","comments":true,"path":"2017/07/10/13-hitltp-tools/","link":"","permalink":"http://yoursite.com/2017/07/10/13-hitltp-tools/","excerpt":"pyltp安装及模型下载可以使用pip直接安装，如果安装失败，建议下载源码进行手动编译。1pip install pyltp 安装pyltp后，下载模型文件，百度云地址在这。我下载的是ltp-data-v3.3.1.tar.bz2。然后将下载到的模型解压，存放在任意地方。注意：版本对应 pyltp版本：0.1.9 LTP版本：3.3.2 模型版本：3.3.1","text":"pyltp安装及模型下载可以使用pip直接安装，如果安装失败，建议下载源码进行手动编译。1pip install pyltp 安装pyltp后，下载模型文件，百度云地址在这。我下载的是ltp-data-v3.3.1.tar.bz2。然后将下载到的模型解压，存放在任意地方。注意：版本对应 pyltp版本：0.1.9 LTP版本：3.3.2 模型版本：3.3.1 上面两步都完成后，我们就可以使用pyltp进行一些文本操作了，例如：分句，分词，词性标注，命名实体识别以及依存句法等。 pyltp语言云的使用分句 - SentenceSplitter123from pyltp import SentenceSplittersentence = SentenceSplitter.split(&apos;我是逗号，我是句号。我是问号？我是感叹号！&apos;)print &apos;\\n&apos;.join(sentence) 分句结果如下：123我是逗号，我是句号。我是问号？我是感叹号！ 分词 - Segmentor12345678910import osLTP_DATA_DIR = &apos;/path/to/your/ltp_data&apos; # ltp模型目录的路径cws_model_path = os.path.join(LTP_DATA_DIR, &apos;cws.model&apos;) # 分词模型路径，模型名称为`cws.model`from pyltp import Segmentorsegmentor = Segmentor() # 初始化实例segmentor.load(cws_model_path) # 加载模型words = segmentor.segment(&apos;欧几里得是西元前三世纪的希腊数学家。&apos;) # 分词print &apos; &apos;.join(words)segmentor.release() # 释放模型 分词结果如下，【欧几里得】被拆成了四个单独的字。1欧 几 里 得 是 西元前 三 世纪 的 希腊 数学家 。 pyltp分词支持用户使用自定义词典。分词外部词典本身是一个文本文件，每行指定一个词，编码须为 UTF-8，样例如下所示:12欧几里得亚里士多德 使用自定义词典进行分词的模型加载方式如下：12345segmentor = Segmentor() # 初始化实例segmentor.load_with_lexicon(cws_model_path, &apos;/path/to/your/lexicon&apos;) # 加载模型，参数lexicon是自定义词典的文件路径words = segmentor.segment(&apos;欧几里得是西元前三世纪的希腊数学家。&apos;)print &apos; &apos;.join(words)segmentor.release() 自定义词典，分词结果如下，分词效果明显得到改善。1欧几里得 是 西元前 三 世纪 的 希腊 数学家 。 词性标注 - Postagger1234567891011pos_model_path = os.path.join(LTP_DATA_DIR, &apos;pos.model&apos;) # 词性标注模型路径，模型名称为`pos.model`from pyltp import Postaggerpostagger = Postagger() # 初始化实例postagger.load(pos_model_path) # 加载模型words = [&apos;欧几里得&apos;, &apos;是&apos;, &apos;西元前&apos;, &apos;三&apos;, &apos;世纪&apos;, &apos;的&apos;, &apos;希腊&apos;, &apos;数学家&apos;, &apos;。&apos;]postags = postagger.postag(words) # 词性标注print &apos; &apos;.join(postags)postagger.release() # 释放模型 词性标注结果如下，如果想了解更多的词性含义。请参考语言云词性标注简介。12345678910nh v nt m n u ns n wp# 欧几里得 - nh - 人名# 是 - v - 动词# 西元前 - nt - 时间名词# 三 - m - 数字# 世纪 - n - 普通名词# 的 - u - 助词# 希腊 - ns - 地理名词# 数学家- n - 普通名词# 。 - wp - 标点符号 命名实体识别 - NamedEntityRecognizer123456789101112ner_model_path = os.path.join(LTP_DATA_DIR, &apos;ner.model&apos;) # 命名实体识别模型路径，模型名称为`ner.model`from pyltp import NamedEntityRecognizerrecognizer = NamedEntityRecognizer() # 初始化实例recognizer.load(ner_model_path) # 加载模型words = [&apos;欧几里得&apos;, &apos;是&apos;, &apos;西元前&apos;, &apos;三&apos;, &apos;世纪&apos;, &apos;的&apos;, &apos;希腊&apos;, &apos;数学家&apos;, &apos;。&apos;]postags = [&apos;nh&apos;, &apos;v&apos;, &apos;nt&apos;, &apos;m&apos;, &apos;n&apos;, &apos;u&apos;, &apos;ns&apos;, &apos;n&apos;, &apos;wp&apos;]nertags = recognizer.recognize(words, postags) # 命名实体识别print &apos; &apos;.join(nertags)recognizer.release() # 释放模型 命名实体结果如下，ltp命名实体类型为：人名（Nh），地名（NS），机构名（Ni）；ltp采用BIESO标注体系。B表示实体开始词，I表示实体中间词，E表示实体结束词，S表示单独成实体，O表示不构成实体。123S-Nh O O O O O S-Ns O O# 欧几里得 - S-Nh - 人名# 希腊 - S-Ns - 地名 依存句法分析 - Parser123456789101112131415161718par_model_path = os.path.join(LTP_DATA_DIR, &apos;parser.model&apos;) # 依存句法分析模型路径，模型名称为`parser.model`from pyltp import Parserparser = Parser() # 初始化实例parser.load(par_model_path) # 加载模型words = [&apos;欧几里得&apos;, &apos;是&apos;, &apos;西元前&apos;, &apos;三&apos;, &apos;世纪&apos;, &apos;的&apos;, &apos;希腊&apos;, &apos;数学家&apos;, &apos;。&apos;]postags = [&apos;nh&apos;, &apos;v&apos;, &apos;nt&apos;, &apos;m&apos;, &apos;n&apos;, &apos;u&apos;, &apos;ns&apos;, &apos;n&apos;, &apos;wp&apos;]arcs = parser.parse(words, postags) # 句法分析rely_id = [arc.head for arc in arcs] # 提取依存父节点idrelation = [arc.relation for arc in arcs] # 提取依存关系heads = [&apos;Root&apos; if id == 0 else words[id-1] for id in rely_id] # 匹配依存父节点词语for i in range(len(words)): print relation[i] + &apos;(&apos; + words[i] + &apos;, &apos; + heads[i] + &apos;)&apos;parser.release() # 释放模型 依存句法分析，输出结果如下，关于依存句法分析，详细参照语言云依存句法简介。123456789SBV(欧几里得, 是)HED(是, Root)ATT(西元前, 世纪)ATT(三, 世纪)ATT(世纪, 数学家)RAD(的, 世纪)ATT(希腊, 数学家)VOB(数学家, 是)WP(。, 是)","categories":[{"name":"辅助工具","slug":"辅助工具","permalink":"http://yoursite.com/categories/辅助工具/"}],"tags":[{"name":"ltp","slug":"ltp","permalink":"http://yoursite.com/tags/ltp/"},{"name":"语言云","slug":"语言云","permalink":"http://yoursite.com/tags/语言云/"}]},{"title":"Theano - 广播","slug":"09-Theano-08","date":"2017-05-08T07:30:16.000Z","updated":"2017-07-17T15:10:24.045Z","comments":true,"path":"2017/05/08/09-Theano-08/","link":"","permalink":"http://yoursite.com/2017/05/08/09-Theano-08/","excerpt":"广播（Broadcasting)广播是这样的一个机制：它允许不同维度的张量进行加法或者乘法运算。在运算时，他将会沿着维度缺失的方向复制较小的那个张量。 通过广播机制，一个标量可以被加到矩阵上，一个向量可以被加到矩阵上，或者一个标量可以被加到向量上。","text":"广播（Broadcasting)广播是这样的一个机制：它允许不同维度的张量进行加法或者乘法运算。在运算时，他将会沿着维度缺失的方向复制较小的那个张量。 通过广播机制，一个标量可以被加到矩阵上，一个向量可以被加到矩阵上，或者一个标量可以被加到向量上。 如上图，广播一个行矩阵。T和F分别表示True和False,指明沿着哪个维度可以进行广播。如果第二个参数是向量，它的形状为（2，）以及它的广播模式为（False,）。它将会自动向左展开，匹配矩阵的维度，最终得到（1,2）和（True,Fale）。 不像numpy那样动态地进行广播，Theano需要知道哪些维度需要进行广播。当可用的时候，广播信息将会以变量的类型给出。 下面的代码说明为了和矩阵执行加法运算，行和列怎么进行广播的：123456789101112131415161718192021222324252627282930313233343536import theanoimport numpyimport theano.tensor as Tr = T.row()r.broadcastable# (True, False)mtr = T.matrix()mtr.broadcastable# (False, False)f_row = theano.function([r, mtr], [r + mtr])R = numpy.arange(3).reshape(1,3)R# array([[0, 1, 2]])M = numpy.arange(9).reshape(3, 3)M# array([[0, 1, 2],# [3, 4, 5],# [6, 7, 8]])f_row(R, M)# [array([[ 0., 2., 4.],# [ 3., 5., 7.],# [ 6., 8., 10.]])]c = T.col()c.broadcastable# (False, True)f_col = theano.function([c, mtr], [c + mtr])C = numpy.arange(3).reshape(3, 1)C# array([[0],# [1],# [2]])M = numpy.arange(9).reshape(3, 3)f_col(C, M)# [array([[ 0., 1., 2.],# [ 4., 5., 6.],# [ 8., 9., 10.]])]","categories":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/tags/Python/"},{"name":"Theano","slug":"Theano","permalink":"http://yoursite.com/tags/Theano/"}]},{"title":"Theano - 处理形状信息","slug":"08-Theano-07","date":"2017-05-07T07:30:16.000Z","updated":"2017-07-17T14:54:35.412Z","comments":true,"path":"2017/05/07/08-Theano-07/","link":"","permalink":"http://yoursite.com/2017/05/07/08-Theano-07/","excerpt":"Theano是怎么处理形状信息(Shape Information)在构建图的时候，不可能严格执行Theano变量的形状。因为在运行的时候，传递给Theano函数的某一参数的值可能影响Thenao变量的形状。目前，关于形状信息的使用在Theano中有以下两种方式： 在输出形状已知的情况下，生成在CPU和GPU上进行2d卷积的更高效的C代码 当我们只关心变量的形状，而不是实际值的时候，将移除图的计算。这通过Op.infer_shape完成。","text":"Theano是怎么处理形状信息(Shape Information)在构建图的时候，不可能严格执行Theano变量的形状。因为在运行的时候，传递给Theano函数的某一参数的值可能影响Thenao变量的形状。目前，关于形状信息的使用在Theano中有以下两种方式： 在输出形状已知的情况下，生成在CPU和GPU上进行2d卷积的更高效的C代码 当我们只关心变量的形状，而不是实际值的时候，将移除图的计算。这通过Op.infer_shape完成。 例子：12345678910import theanoimport theano.tensor as Tx = T.matrix(&apos;x&apos;)f = theano.function([x], (x ** 2).shape)theano.printing.debugprint(f)# MakeVector&#123;dtype=&apos;int64&apos;&#125; [id A] &apos;&apos; 2# |Shape_i&#123;0&#125; [id B] &apos;&apos; 1# | |x [id C]# |Shape_i&#123;1&#125; [id D] &apos;&apos; 0# |x [id C] 输出结果不包含任何乘法以及幂运算。Theano已经移除了它们直接去计算输出的形状。 形状推断问题（Shape Inference Problem）在图中，Theano将会传播形状的信息。有时，这将会导致一些错误。考虑下面的例子：123456789101112131415161718192021222324252627282930313233import numpyimport theanox = theano.tensor.matrix(&apos;x&apos;)y = theano.tensor.matrix(&apos;y&apos;)z = theano.tensor.join(0, x, y) # 将x,y按行拼接起来，要求x,y的列数一致xv = numpy.random.rand(5, 4)yv = numpy.random.rand(3, 3)f = theano.function([x, y], z.shape)theano.printing.debugprint(f)# MakeVector&#123;dtype=&apos;int64&apos;&#125; [id A] &apos;&apos; 4# |Elemwise&#123;Add&#125;[(0, 0)] [id B] &apos;&apos; 3# | |Shape_i&#123;0&#125; [id C] &apos;&apos; 1# | | |x [id D]# | |Shape_i&#123;0&#125; [id E] &apos;&apos; 2# | |y [id F]# |Shape_i&#123;1&#125; [id G] &apos;&apos; 0# |x [id D]f(xv, yv) # 并没有报错# array([8, 4])f = theano.function([x,y], z) # 直接返回ztheano.printing.debugprint(f)# Join [id A] &apos;&apos; 0# |TensorConstant&#123;0&#125; [id B]# |x [id C]# |y [id D]f(xv, yv) # 报错# Traceback (most recent call last):# ...# ValueError: ... 正如你看到的，当仅仅访问计算结果的形状信息(z.shape)时，将会直接推断结果的形状，并不会执行计算过程（即z的具体数值）。 这使得形状的计算速度很快，但是它可能会隐藏一些错误。在这个例子中，输出结果形状的计算仅仅基于输入的第一个Theano变量，这导致返回形状信息的错误。 这种现象也可能出现在其他运算上，比如elemwise和dot。事实上，为了执行一些优化（例如，速度和稳定性），Theano从一开始就假定计算是正确的，并且是一致的。就像上述例子中一样。你可以通过使用Theano标志optimizer_excluding=local_shape_to_shape_i运行代码（将不会执行上述提及的优化）来检测这种错误。你也可以通过在FAST_COMPILE或者DebugMode模式下执行代码，得到同样的效果。 FAST_COMPILE模式将不会执行这种优化，以及大部分其它的优化。 DebugMode模式将会在优化前以及优化后进行测试，导致运行速率更慢。 指定确切的形状目前，指定一个形状并不像我们计划一些更新和期望的那么容易和灵活。以下情形是目前我们可以做到的： 当调用conv2d时，你可以直接把形状信息传递给ConvOp。你只需要在调用时简单地设置一下image_shape和filter_shape参数就可以了。他们必须是包含4个元素的元组。例如： 1theano.tensor.nnet.conv2d(..., image_shape=(7,3,5,5), filter_shape=(2,3,4,4)) 你可以在图的任何位置使用SpecifyShape添加位置信息。这允许执行一些优化。在接下来的例子中，这使得预先计算Theano函数为常数成为可能。 12345import theanox = theano.tensor.matrix()x_specify_shape = theano.tensor.specify_shape(x, (2,2))f = theano.function([x], (x_specify_shape ** 2).shape)theano.printing.debugprint(f)","categories":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/tags/Python/"},{"name":"Theano","slug":"Theano","permalink":"http://yoursite.com/tags/Theano/"}]},{"title":"Theano - 循环","slug":"07-Theano-06","date":"2017-05-06T07:30:16.000Z","updated":"2017-07-17T14:53:08.898Z","comments":true,"path":"2017/05/06/07-Theano-06/","link":"","permalink":"http://yoursite.com/2017/05/06/07-Theano-06/","excerpt":"Scan 复发(Recurrence)的一种常用形式，可以用于循环(looping) Reduction和map是scan的特例 可以根据一些输出序列scan一个函数（function)，每一步都会生成一个输出 可以查看之前k步的输出 给定一个初始状态z=0,可以通过scan函数z + x(i)计算一个列表的和sum(a_list) 通常一个for循环可以用scan()操作符进行实现 使用scan的优点： 迭代次数为符号图的一部分 最大限度地减少GPU传输（如果用到了GPU） 通过序列步长计算梯度 运行速率比python内置的for循环稍微快些 可以通过检测需要的实际内存量，来降低整体内存使用量","text":"Scan 复发(Recurrence)的一种常用形式，可以用于循环(looping) Reduction和map是scan的特例 可以根据一些输出序列scan一个函数（function)，每一步都会生成一个输出 可以查看之前k步的输出 给定一个初始状态z=0,可以通过scan函数z + x(i)计算一个列表的和sum(a_list) 通常一个for循环可以用scan()操作符进行实现 使用scan的优点： 迭代次数为符号图的一部分 最大限度地减少GPU传输（如果用到了GPU） 通过序列步长计算梯度 运行速率比python内置的for循环稍微快些 可以通过检测需要的实际内存量，来降低整体内存使用量 例子：对应元素计算tanh(x(t).dot(W) + b)123456789101112131415161718192021import theanoimport theano.tensor as Timport numpy as np# 定义张量变量X = T.matrix(&apos;X&apos;)W = T.matrix(&apos;W&apos;)b_sym = T.vector(&apos;b_sym&apos;)results, updates = theano.scan(lambda v: T.tanh(T.dot(v, W) + b_sym), sequences=X)compute_elementwise = theano.function([X, W, b_sym], results)# 测试x = np.eye(2, dtype=theano.config.floatX)w = np.ones((2, 2), dtype=theano.config.floatX)b = np.ones((2), dtype=theano.config.floatX)b[1] = 2compute_elementwise(x, w, b)# 和numpy相比较np.tanh(x.dot(w) + b) 例子： 计算序列x(t) = tanh(x(t-1).dot(W) + y(t).dot(U) + p(T-t).dot(V))123456789101112131415161718192021222324252627282930313233import theanoimport theano.tensor as Timport numpy as np# 定义张量变量X = T.vector(&apos;X&apos;)W = T.matrix(&apos;W&apos;)b_sym = T.vector(&apos;b_sym&apos;)U, Y, V, P = T.matrices(&apos;U&apos;, &apos;Y&apos;, &apos;V&apos;, &apos;P&apos;)result, update = theano.scan(lambda y, p, x_tml: T.tanh(T.dot(x_tml, W) + T.dot(y, U) + T.dot(p, V)), sequences=[Y, P[::-1]], outputs_info=[X])compute_seq = theano.function(inputs=[X, W, Y, U, P, V], outputs=result)# 测试x = np.zeros((2), dtype=theano.config.floatX)x[1] = 1w = np.ones((2, 2), dtype=theano.config.floatX)y = np.ones((5, 2), dtype=theano.config.floatX)y[0, :] = -3u = np.ones((2, 2), dtype=theano.config.floatX)p = np.ones((5, 2), dtype=theano.config.floatX)p[0, :] = 3v = np.ones((2, 2), dtype=theano.config.floatX)print(compute_seq(x, w, y, u, p, v))# 与Numpy对比x_res = np.zeros((5, 2), dtype=theano.config.floatX)x_res[0] = np.tanh(x.dot(w) + y[0].dot(u) + p[4].dot(v))for i in range(1, 5): x_res[i] = np.tanh(x_res[i - 1].dot(w) + y[i].dot(u) + p[4-i].dot(v))print(x_res) 例子： 计算X的行范式123456789101112131415import theanoimport theano.tensor as Timport numpy as np# 定义张量变量X = T.matrix(&apos;X&apos;)results, updates = theano.scan(lambda x_i: T.sqrt((x_i ** 2)).sum(), sequences=[X])compute_norm_lines = theano.function(inputs=[X], outputs=results)# 测试x = np.diag(np.arange(1, 6, dtype=theano.config.floatX), 1)print(compute_norm_lines(x))# 和Numpy对比print(np.sqrt((x ** 2).sum(1))) 例子： 计算X的列范式123456789101112131415import theanoimport theano.tensor as Timport numpy as np# 定义张量变量X = T.matrix(&quot;X&quot;)results, updates = theano.scan(lambda x_i: T.sqrt((x_i ** 2).sum()), sequences=[X.T])compute_norm_cols = theano.function(inputs=[X], outputs=results)# 测试x = np.diag(np.arange(1, 6, dtype=theano.config.floatX), 1)print(compute_norm_cols(x))# 和Numpy对比print(np.sqrt((x ** 2).sum(0)))","categories":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/tags/Python/"},{"name":"Theano","slug":"Theano","permalink":"http://yoursite.com/tags/Theano/"}]},{"title":"Theano - 条件","slug":"06-Theano-05","date":"2017-05-05T07:30:16.000Z","updated":"2017-07-17T14:51:34.442Z","comments":true,"path":"2017/05/05/06-Theano-05/","link":"","permalink":"http://yoursite.com/2017/05/05/06-Theano-05/","excerpt":"IfElse vs Switch IfElse接收布尔型条件和两个变量作为输入。 Switch接收一个张量（Tensor）以及两个变量作为输入。 Switch进行元素级运算，因此比IfElse更常用。 IfElse比较懒惰，只计算满足条件的相应输出变量， 而Switch计算所有的输出变量。 即： ifelse(condition, output1, output2): 如果condition:1(0),那么ifelse只计算output1(output2)并输出。 switch(condition, output1, output2): 如果condition:1(0),那么switch计算output1和output2，并输出output1(output2)","text":"IfElse vs Switch IfElse接收布尔型条件和两个变量作为输入。 Switch接收一个张量（Tensor）以及两个变量作为输入。 Switch进行元素级运算，因此比IfElse更常用。 IfElse比较懒惰，只计算满足条件的相应输出变量， 而Switch计算所有的输出变量。 即： ifelse(condition, output1, output2): 如果condition:1(0),那么ifelse只计算output1(output2)并输出。 switch(condition, output1, output2): 如果condition:1(0),那么switch计算output1和output2，并输出output1(output2) 12345678910111213141516171819202122232425262728from theano import tensor as Tfrom theano.ifelse import ifelseimport theano, time, numpya, b = T.scalars(&apos;a&apos;, &apos;b&apos;)x, y = T.matrices(&apos;x&apos;, &apos;y&apos;)z_switch = T.switch(T.lt(a, b), T.mean(x), T.mean(y))z_ifelse = ifelse(T.lt(a, b), T.mean(x), T.mean(y))f_switch = theano.function([a, b, x, y], z_switch, mode=theano.Mode(linker=&apos;vm&apos;))f_ifelse = theano.function([a, b, x, y], z_ifelse, mode=theano.Mode(linker=&apos;vm&apos;))val1 = 0.val2 = 1.big_mat1 = numpy.ones((10000, 1000))big_mat2 = numpy.ones((10000, 1000))n_times = 10tic = time.clock()for i in range(n_times): f_switch(val1, val2, big_mat1, big_mat2)print(&apos;time spent evaluating both values %f sec&apos; % (time.clock() - tic))tic = time.clock()for j in range(n_times): f_ifelse(val1, val2, big_mat1, big_mat2)print(&apos;time spent evaluating one value %f sec&apos; % (time.clock() - tic)) 在这个例子中，IfElse比Switch花费更少的时间，因为他只计算输出变量中的一个。如果不使用linker=’vm’或linker=’cvm’，那么ifelse将会和switch一样计算两个输出变量，而且花费的时间和switch一样多。","categories":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/tags/Python/"},{"name":"Theano","slug":"Theano","permalink":"http://yoursite.com/tags/Theano/"}]},{"title":"Theano - 导数","slug":"05-Theano-04","date":"2017-05-04T07:30:16.000Z","updated":"2017-07-17T14:49:44.421Z","comments":true,"path":"2017/05/04/05-Theano-04/","link":"","permalink":"http://yoursite.com/2017/05/04/05-Theano-04/","excerpt":"计算梯度计算x^2的梯度123456789101112import numpyimport theanoimport theano.tensor as Tfrom theano import ppx = T.dscalar(&apos;x&apos;)y = x ** 2gy = T.grad(y, x)pp(gy)f = theano.function([x], gy)pp(f.maker.fgraph.outputs[0])f(4)numpy.allclose(f(94.2), 188.4) 计算逻辑函数的梯度12345x = T.dmatrix(&apos;x&apos;)s = T.sum(1 / (1 + T.exp(-x)))gs = T.grad(s, x)dlogistic = theano.function([x], gs)dlogistic([[0, 1], [-1, -2]])","text":"计算梯度计算x^2的梯度123456789101112import numpyimport theanoimport theano.tensor as Tfrom theano import ppx = T.dscalar(&apos;x&apos;)y = x ** 2gy = T.grad(y, x)pp(gy)f = theano.function([x], gy)pp(f.maker.fgraph.outputs[0])f(4)numpy.allclose(f(94.2), 188.4) 计算逻辑函数的梯度12345x = T.dmatrix(&apos;x&apos;)s = T.sum(1 / (1 + T.exp(-x)))gs = T.grad(s, x)dlogistic = theano.function([x], gs)dlogistic([[0, 1], [-1, -2]]) 计算Jacobian12345x = T.dvector(&apos;x&apos;)y = x ** 2J, updates = theano.scan(lambda i, y, x: T.grad(y[i], x), sequences=T.arange(y.shape[0]), non_sequences=[y,x])f = theano.function([x], J, updates=updates)f([4, 4]) 计算Hessian矩阵1234567x = T.dvector(&apos;x&apos;)y = x ** 2cost = y.sum()gy = T.grad(cost, x)H, updates = theano.scan(lambda i, gy, x: T.grad(gy[i], x), sequences=T.arange(gy.shape[0]), non_sequences=[gy,x])f = theano.function([x], H, updates=updates)f([4,4]) Jacobian times a Vector右算子(R-operator)1234567W = T.dmatrix(&apos;W&apos;)V = T.dmatrix(&apos;V&apos;)x = T.dvector(&apos;x&apos;)y = T.dot(x, W)JV = T.Rop(y, W, V)f = theano.function([W, V, x], JV)f([[1,1], [1,1]], [[2,2], [2,2]], [0,1]) 左算子（L-operator)1234567W = T.dmatrix(&apos;W&apos;)v = T.dvector(&apos;v&apos;)x = T.dvector(&apos;x&apos;)y = T.dot(x, W)VJ = T.Lop(y, W, v)f = theano.function([v, x], VJ)f([2,2], [0,1]) Hessian times a Vector1234567x = T.dvector(&apos;x&apos;)v = T.dvector(&apos;v&apos;)y = T.sum(x ** 2)gy = T.grad(y, x)vH = T.grad(T.sum(gy * v), x)f = theano.function([x,v], vH)f([4,4], [2,2]) 右算子1234567x = T.dvector(&apos;x&apos;)v = T.dvector(&apos;v&apos;)y = T.sum(x ** 2)gy = T.grad(y, x)Hv = T.Rop(gy, x, v)f = theano.function([x,v], Hv)f([4,4], [2,2])","categories":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/tags/Python/"},{"name":"Theano","slug":"Theano","permalink":"http://yoursite.com/tags/Theano/"}]},{"title":"Theano - 更多的例子","slug":"04-Theano-03","date":"2017-05-03T07:30:16.000Z","updated":"2017-07-17T14:48:02.259Z","comments":true,"path":"2017/05/03/04-Theano-03/","link":"","permalink":"http://yoursite.com/2017/05/03/04-Theano-03/","excerpt":"Logistic函数12345678910import theanoimport theano.tensor as Tx = T.dmatrix(&apos;x&apos;)s = 1 / (1 + T.exp(-x))logistic = theano.function([x], s)logistic([[0, 1], [-1, -2]])# s(x) = 1/(1+exp(-x)) = (1+tanh(x/2))/2s2 = (1 + T.tanh(x / 2)) / 2logistic2 = theano.function([x], s2)logistic2([[0, 1], [-1, -2]]) 同时执行多种计算任务Theano支持多种输出的函数。例如，我们可以同时计算两个矩阵a,b相应元素之间的差、绝对差、平方差。当我们调用函数f是，返回三个变量：","text":"Logistic函数12345678910import theanoimport theano.tensor as Tx = T.dmatrix(&apos;x&apos;)s = 1 / (1 + T.exp(-x))logistic = theano.function([x], s)logistic([[0, 1], [-1, -2]])# s(x) = 1/(1+exp(-x)) = (1+tanh(x/2))/2s2 = (1 + T.tanh(x / 2)) / 2logistic2 = theano.function([x], s2)logistic2([[0, 1], [-1, -2]]) 同时执行多种计算任务Theano支持多种输出的函数。例如，我们可以同时计算两个矩阵a,b相应元素之间的差、绝对差、平方差。当我们调用函数f是，返回三个变量： 12345678import theanoimport theano.tensor as Ta, b = T.dmatrices(&apos;a&apos;, &apos;b&apos;)diff = a - babs_diff = abs(diff)diff_squared = diff ** 2f = theano.function([a, b], [diff, abs_diff, diff_squared])f([[1, 1], [1, 1]], [[0, 1], [2, 3]]) 为参数设置默认值假设我们要定义一个实现两个数字加法的函数。如果你仅仅提供一个数字，另一个数字假设(默认)为1,就可以这么做：1234567from theano import In, functionimport theano.tensor as Tx, y = T.dscalars(&apos;x&apos;, &apos;y&apos;)z = x + yf = function([x, In(y, value=1)], z)f(33)f(33, 2) 含有默认值的输入必须位于不含默认值的输入之后（和python的函数类似）。允许多个输入含有默认值，这些参数可以通过位置设定，也可以通过名字进行设定。12345678x, y, w = T.dscalars(&apos;x&apos;, &apos;y&apos;, &apos;w&apos;)z = (x + y) * wf = function([x, In(y, value=1), In(w, value=2, name=&apos;w_by_name&apos;)], z)f(33)f(33, 2)f(33, 0, 1)f(33, w_by_name=1)f(33, w_by_name=1, y=0) In 不知道通过参数传递的局部变量x,y的名字。符号变量对象拥有名字（name）属性（在上本例中通过dscalars进行设置），这也是我们构建函数function关键字参数的名字。通过In(y, value=1)这一机制实现。在In(w, value=2, name=’w_by_name’)中，我们重写了符号变量的名字属性。所有当我们通过f(x=33, y=0, w=1)的形式调用函数时，就会出错。w应该改为w_by_name. 使用共享变量我们也可以构建一个含有内状态（internal state）的函数。例如,假设我们要构造一个累加函数（accumulator）:初始状态设置为0。接着，每次调用函数，状态就会通过函数的参数自动增加。12345678910111213141516171819202122232425262728293031# 首先，我们定义一个累加函数。它将自己的内状态加上它的参数，然后返回旧状态的值。import theanoimport theano.tensor as Tfrom theano import sharedstate = shared(0)inc = T.iscalar(&apos;inc&apos;)accumulator = function([inc], state, updates=[(state, state+inc)])# state的值可以通过.get_value()和.set_value()惊行获取和修改state.get_value()accumulator(1)state.get_value()accumulator(300)state.get_value()state.set_value(-1)accumulator(3)state.get_value()# 我们可以构造多个函数，使用相同共享变量，这些函数都可以更新状态的值decrementor = function([inc], state, updates=[(state, state-inc)])decrementor(2)state.get_value()# 可能你会使用一个共享变量表达多个公式，但是你并不想使用共享变量的值。# 这种情况下，你可以使用function中的givens参数。fn_of_state = state * 2 + incfoo = T.scalar(dtype=state.dtype) # foo的类型必须和将要通过givens取代的共享变量的类型保持一致skip_shared = function([inc, foo], fn_of_state, givens=[(state, foo)])skip_shared(1, 3) # 我们正在使用3作为state,并非state.valuestate.get_value() # 旧的状态(state)一直存在，但是我们使用它。 复制函数（copying functions)Theano中的函数可以被复制，被用于构造相似的函数（拥有不同的共享变量和更新），这可以通过function中的copy()实现。让我们从以上定义的累加函数(accumulator)开始：123456789101112131415161718192021import theanoimport theano.tensor as Tstate = theano.shared(0)inc = T.iscalar(&apos;inc&apos;)accumulator = function([inc], state, updates=[(state, state+inc)])# 我们可以像平常一样增加它的状态（state）accumulator(10)state.get_value()# 我们可以用copy()创建一个相似的累加器(accumulator)，但是可以通过swap参数拥有自己的内状态,# swap参数是将要交换的共享参数字典new_state = theano.shared(0)new_accumulator = accumulator.copy(swap=&#123;state:new_state&#125;)new_accumulator(100)new_state.get_value()state.get_value()# 现在我们创建一个复制，但是使用delete_updates参数移除更新，此时，默认为False# 此时，共享状态将不会再更新。null_accumulator = accumulator.copy(delete_updates=True)null_accumulator(9000)state.get_value() 使用随机数（Using Random Numbers)简洁的例子123456789101112131415161718192021222324from theano.tensor.shared_randomstreams import RandomStreamsfrom theano import functionsrng = RandomStreams(seed=324)rv_u = srng.uniform((2,2))rv_n = srng.normal((2,2))f = function([], rv_u)g = function([], rv_n, no_default_updates=True) # 不更新rv_n.rngnearly_zeros = function([], rv_u + rv_u - 2 * rv_u)# rv_u表示服从均匀分布的2*2随机数矩阵# rv_n表示服从正太分布的2*2随机数矩阵# 现在我们来调用这些对象。如果调用f()，我们将会得到随机均匀分布数。# 随机数产生器的内状态将会自动更新，所以我们每次调用f()时将会得到不同的随机数f_val0 = f()f_val1 = f()# 当我们添加额外的参数no_default_updates=True（在函数g中）后，随机数产生器的状态将不会受调用函数的影响。# 例如：多次调用g()将会返回相同的随机数,g_val0和g_val1相同。g_val0 = g()g_val1 = g()# 一个重要的观点是：一个随机变量在一次调用函数期中最多只能构建一次。# 所以nearly_zeros函数保证了输出近似为0，尽管rv_u随机变量在输出表达式中出现了3次。nearly_zeros() 种子流（Seeding Streams）随机变量可以单独也可以共同产生，你可以通过对.rng属性进行seeding或者使用.rng.set_value()对.rng进行赋值产生一个随机变量。123456rng_val = rv_u.rng.get_value(borrow=True) # 获取rv_u的rng(随机数生成器)rng_val.seed(89234) # 对generator(生成器）进行seeds（播种）rv_u.rng.set_value(rng_val, borrow=True) # 对rng进行赋值# 你可以seed由RandomStreams对象分配的所有随机变量。srng.seed(902340) 函数之间共享流（Sharing Streams Between Functions）像共享变量一样，随机变量使用的随机数生成器在不同函数之间是相同的。所以我们的nearly_zeros函数将会更新f函数使用的生成器的状态。例如：12345678state_after_v0 = rv_u.rng.get_value().get_state()nearly_zeros() # 这将会影响rv_u的生成器v1 = f()rng = rv_u.rng.get_value(borrow=True)rng.set_state(state_after_v0)rv_u.rng.set_value(rng, borrow=True)v2 = f() # v2 != v1v3 = f() # v3 == v1 在Theano Graphs之间复制随机状态在很多应用场景中，使用者可能想把一个theano graph（图：g1,内置函数：f1）中的所有随机数生成器的状态传递给第二个theano graph（图：g2,内置函数：f2)。 例如：如果你试图从之前储存模型的参数中，初始化一个模型的状态，将会出现上述需要。theano.tensor.shared_randomstreams.RandomStreams和theano.sandbox.rng_mrg.MRG_RandomStreams这些在state_updates参数的复制元素可以实现。 每一次从RandomStreams对象中生成一个随机变量，将会有一个元组添加到state_update列表中。 第一个元素是共享变量：它表示和特定变量相关的随机数生成器的状态。第二个元素表示和随机数生成过程相对应的theano graph。 下面的例子展示了：随机状态(random states)如何从一个theano function 传递给另一个theano function中的。1234567891011121314151617181920212223242526272829303132333435import theanoimport numpyimport theano.tensor as Tfrom theano.sandbox.rng_mrg import MRG_RandomStreamsfrom theano.tensor.shared_randomstreams import RandomStreamsclass Graph: def __init__(self, seed=123): self.rng = RandomStreams(seed) self.y = self.rng.uniform(size=(1,))g1 = Graph(seed=123)f1 = theano.function([], g1.y)g2 = Graph(seed=987)f2 = theano.function([], g2.y)# 默认情况下，两个函数f1,f2不同步f1()f2()def copy_random_state(g1, g2): if isinstance(g1.rng, MRG_RandomStreams): g2.rng.rstate = g1.rng.rstate for (su1, su2) in zip(g1.rng.state_updates, g2.rng.state_updates): su2[0].set_value(su1[0].get_value())# 现在我们赋值theano随机数生成器的状态copy_random_state(g1, g2)f1()f2() 一个真实的例子：逻辑回归12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758import numpyimport theanoimport theano.tensor as Trng = numpy.randomN = 400 # training sample sizefeats = 784 # number of input variables# generate a data set: D = (input_values, target_class)D = (rng.rand(N, feats), rng.randint(size=N, low=0, high=2))training_steps = 10000# Declare Theano symbolic variablesx = T.dmatrix(&apos;x&apos;)y = T.dvector(&apos;y&apos;)# initialize the weight vector w randomly## this and the following bias variable b# are shared so they keep their values# between training iterations (updates)w = theano.shared(rng.randn(feats), name=&apos;w&apos;)# initialize the bias termb = theano.shared(0., name=&apos;b&apos;)print(&apos;Initial model:&apos;)print(w.get_value())print(b.get_value())# Construct Theano expression graphp_1 = 1 / (1 + T.exp(-T.dot(x, w) - b)) # Probability that target = 1prediction = p_1 &gt; 0.5 # The prediction thresholdedxent = -y * T.log(p_1) - (1-y) * T.log(1-p_1) # Cross-entropy loss functioncost = xent.mean() + 0.01 * (w ** 2).sum() # The cost to minimizegw, gb = T.grad(cost, [w, b]) # Compute the gradient of the cost# Compiletrain = theano.function( inputs=[x,y], outputs=[prediction, xent], updates=((w, w - 0.1 * gw), (b, b - 0.1 * gb)))predict = theano.function(inputs=[x], outputs=prediction)# Trainfor i in range(training_steps): pred, err = train(D[0], D[1])print(&apos;Final model:&apos;)print(w.get_value())print(b.get_value())print(&apos;target values for D:&apos;)print(D[1])print(&apos;prediction on D:&apos;)print(predict(D[0]))","categories":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/tags/Python/"},{"name":"Theano","slug":"Theano","permalink":"http://yoursite.com/tags/Theano/"}]},{"title":"Theano - 代数","slug":"03-Theano-02","date":"2017-05-02T07:30:16.000Z","updated":"2017-07-17T14:47:30.690Z","comments":true,"path":"2017/05/02/03-Theano-02/","link":"","permalink":"http://yoursite.com/2017/05/02/03-Theano-02/","excerpt":"两个标量的加法为了让我们开始使用Theano，以及感受theano是如何工作的。接下来，我们构造一个简单的函数：加法。 ## 两个标量的加法1234567891011121314151617181920212223242526import numpyimport theano.tensor as Timport theanofrom theano import function# 定义两个符号（变量）x, y来表示你想实施加法的数。# 换句话说， x,y,z均为变量对象。# 在Theano中，所有的符号必须定义类型。# T.dscalar: 表示双精度（doubles)的0维数组（标量），他是Theano中的类型(Type)x = T.dscalar(&apos;x&apos;)y = T.dscalar(&apos;y&apos;)z = x + y# dscalar不是一个类(class)。因此，事实上x,y都不是dscalr的实例。# 它们是TensorVariable的实例。# 然而，x,y被赋值为theano的dscalar类型。type(x) # theano.tensor.var.TensorVariablex.type # TensorType(float64, scalar)T.dscalar # TensorType(float64, scalar)x.type is T.dscalar # True# 在你运行f时，你会注意到有些延迟# 因为f正在被编译为C代码f = function([x, y], z)f(2, 3)numpy.allclose(f(16.3, 12.1), 28.4)numpy.allcolse(z.eval(&#123;x: 16.3, y: 12.1&#125;), 28.4)","text":"两个标量的加法为了让我们开始使用Theano，以及感受theano是如何工作的。接下来，我们构造一个简单的函数：加法。 ## 两个标量的加法1234567891011121314151617181920212223242526import numpyimport theano.tensor as Timport theanofrom theano import function# 定义两个符号（变量）x, y来表示你想实施加法的数。# 换句话说， x,y,z均为变量对象。# 在Theano中，所有的符号必须定义类型。# T.dscalar: 表示双精度（doubles)的0维数组（标量），他是Theano中的类型(Type)x = T.dscalar(&apos;x&apos;)y = T.dscalar(&apos;y&apos;)z = x + y# dscalar不是一个类(class)。因此，事实上x,y都不是dscalr的实例。# 它们是TensorVariable的实例。# 然而，x,y被赋值为theano的dscalar类型。type(x) # theano.tensor.var.TensorVariablex.type # TensorType(float64, scalar)T.dscalar # TensorType(float64, scalar)x.type is T.dscalar # True# 在你运行f时，你会注意到有些延迟# 因为f正在被编译为C代码f = function([x, y], z)f(2, 3)numpy.allclose(f(16.3, 12.1), 28.4)numpy.allcolse(z.eval(&#123;x: 16.3, y: 12.1&#125;), 28.4) 两个矩阵的加法12345x = T.dmatrix(&apos;x&apos;)y = T.dmatrix(&apos;y&apos;)z = x + yf = function([x, y], z)f([[1, 2], [3, 4]], [[10, 20], [30, 40]]) 可以用到的类型(type)： byte: bscalar, bvector, bmatrix, brow, bcol, btensor3, btensor4, btensro5 16-bit intergers: wscalar, wvector, wmatrix, wrow, wcol, wtensor3, wtensor4, wtensor5 32-bit intergers: iscalar, ivector, imatrix, irow, icol, itensor3, itensor4, itensor5 64-bit intergers: lscalar, lvector, lmatrix, lrow, lcol, ltensor3, ltensor4, ltensor5 float: fscalar, fvector, fmatrix, frow, fcol, ftensor3, ftensor4, ftensor5 double: dscalar, dvector, dmatrix, drow, dcol, dtensor3, dtensor4, dtensor5 complex: cscalar, cvector, cmatrix, crow, ccol, ctensor3, ctensor4, ctensor5 练习1234a = theano.tensor.vector() # 声明一个变量out = a + a ** 10 # 构造一个符号表达式f = theano.function([a], out) # 编译一个函数print(f([0, 1, 2])) 修正并执行上面的代码，使得其能够计算：a ^ 2 + b ^ 2 + 2ab 12345678a = theano.tensor.vector()b = theano.tensor.vector()out1 = a ** 2 + b ** 2 + 2 * a * bout2 = (a + b) ** 2f1 = theano.function([a, b], out1)f2 = theano.function([a, b], out2)print(f1([0, 1], [1, 2]))print(f2([0, 1], [1, 2]))","categories":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/tags/Python/"},{"name":"Theano","slug":"Theano","permalink":"http://yoursite.com/tags/Theano/"}]},{"title":"Theano - numpy新手","slug":"02-Theano-01","date":"2017-05-01T07:30:16.000Z","updated":"2017-07-17T14:45:35.784Z","comments":true,"path":"2017/05/01/02-Theano-01/","link":"","permalink":"http://yoursite.com/2017/05/01/02-Theano-01/","excerpt":"机器学习中的矩阵公约水平方向为矩阵的行，竖直方向为矩阵的列，每一行为一个样例（记录）。 因此输入[10, 5]表示：由10个样例（记录），每个样例具有5个维度（属性）组成的矩阵。如果[10,5]为一个神经网络的输入，那么权重矩阵的表示形式为[5, #hid]的矩阵。考虑一下数组：1234567import numpy as npnp.asarray([[1., 2], [3, 4], [5, 6]])np.asarray([[1., 2], [3, 4], [5, 6]]).shape# 这是一个3*2的矩阵，即有3行2列# 输出矩阵的第3行，第1列元素np.asarray([[1., 2], [3, 4], [5, 6]])[2, 0]","text":"机器学习中的矩阵公约水平方向为矩阵的行，竖直方向为矩阵的列，每一行为一个样例（记录）。 因此输入[10, 5]表示：由10个样例（记录），每个样例具有5个维度（属性）组成的矩阵。如果[10,5]为一个神经网络的输入，那么权重矩阵的表示形式为[5, #hid]的矩阵。考虑一下数组：1234567import numpy as npnp.asarray([[1., 2], [3, 4], [5, 6]])np.asarray([[1., 2], [3, 4], [5, 6]]).shape# 这是一个3*2的矩阵，即有3行2列# 输出矩阵的第3行，第1列元素np.asarray([[1., 2], [3, 4], [5, 6]])[2, 0] 广播(broadcasting)Numpy 在对不同形状的数组进行数学运算时进行广播。通俗的意思就是：较小的数组或标量将会被广播（扩展）形成一个较大尺寸的数组，得到相匹配的形状。例如：123456import numpy as npa = np.asarray([1.0, 2.0, 3.0])b = 2.0a * b # array([2., 4., 6.])# 较小尺寸的b在a*b运算期间，被扩展为和a同样尺寸的数组array([2., 2., 2.])# 这样极大地简化了b的书写，用标量2.0代替array([2.0, 2.0, 2.0])。","categories":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"http://yoursite.com/tags/Python/"},{"name":"Theano","slug":"Theano","permalink":"http://yoursite.com/tags/Theano/"}]}]}